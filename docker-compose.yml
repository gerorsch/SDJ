services:
  # ───────── Banco de Dados ─────────
  postgres:
    image: postgres:13
    container_name: rag_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-rag_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-rag_password}
      POSTGRES_DB: ${POSTGRES_DB:-rag_database}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER:-rag_user}"]
      interval: 10s
      retries: 5
      start_period: 5s
    ports:
      - "5434:5432"  # Porta externa 5434, interna 5432
    networks:
      - network

  # ───────── Search Engine ─────────
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.1
    container_name: rag_elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx1g"
      - network.host=0.0.0.0
      - http.port=9200
    ports:
      - "9200:9200"
    volumes:
      - ./data/elasticsearch:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
      - network

  # ───────── Backend API ─────────
  fastapi:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: rag_api
    restart: always
    env_file:
      - .env
    working_dir: /app
    # Modificado para usar gunicorn com Uvicorn workers (conforme referência)
    command: gunicorn --conf gunicorn_conf.py main:app
    ports:
      - "8010:8001"
    environment:
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${POSTGRES_DB:-rag_database}
      - POSTGRES_USER=${POSTGRES_USER:-rag_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-rag_password}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - LLM_API_URL=https://api.openai.com/v1/chat/completions
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672//
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672//
      - CELERY_RESULT_BACKEND=rpc://
    volumes:
      # Volumes temporários para uploads/outputs
      - uploads_vol:/tmp/uploads
      - outputs_vol:/tmp/outputs
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - network

  # ───────── Broker de Fila ─────────
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: rag_rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER:-guest}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD:-guest}
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - network

  # ───────── Worker Celery ─────────
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: rag_celery_worker
    restart: always
    env_file:
      - .env
    working_dir: /app
    command: celery -A tasks.celery_app worker --loglevel=info --concurrency=2
    environment:
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${POSTGRES_DB:-rag_database}
      - POSTGRES_USER=${POSTGRES_USER:-rag_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-rag_password}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - LLM_API_URL=https://api.openai.com/v1/chat/completions
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672//
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672//
      - CELERY_RESULT_BACKEND=rpc://
    volumes:
      - uploads_vol:/tmp/uploads
      - outputs_vol:/tmp/outputs
      - ./backend:/app
    depends_on:
      rabbitmq:
        condition: service_healthy
      postgres:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    networks:
      - network

  # ───────── Frontend (Next.js + TypeScript) ─────────
  frontend:
    build:
      context: ./frontend-next
      dockerfile: Dockerfile
    container_name: sdj_frontend
    restart: always
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://fastapi:8001
      - NODE_ENV=production
    depends_on:
      fastapi:
        condition: service_started
    networks:
      - network

  # ───────── Proxy Reverso ─────────
  nginx:
    build:
      context: .
      dockerfile: Dockerfile.nginx
    container_name: rag_proxy
    ports:
      - "80:80"
    depends_on:
      - frontend
      - fastapi
    networks:
      - network
    restart: always


networks:
  network:
    driver: bridge

volumes:
  uploads_vol:
    driver: local
  outputs_vol:
    driver: local
  postgres_data:
    driver: local
  elasticsearch_data:
    driver: local
  rabbitmq_data:
    driver: local