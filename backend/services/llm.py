import os
import random
import time
import math
import asyncio
from typing import Callable, Optional, List, Dict, Any
from openai import OpenAI
from anthropic import Anthropic

# Providers
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai").strip().lower()  # 'openai' | 'anthropic'
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-5").strip()
LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.2"))
LLM_MAX_TOKENS = int(os.getenv("LLM_MAX_TOKENS", "128000"))
desired = LLM_MAX_TOKENS
_openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY")) if LLM_PROVIDER == "openai" else None
_anthropic = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")) if LLM_PROVIDER == "anthropic" else None

if LLM_PROVIDER == "openai":
    try:
        from openai import OpenAI  # SDK v1
        _openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    except Exception as e:
        raise RuntimeError(f"Falha ao inicializar OpenAI client: {e}")
elif LLM_PROVIDER == "anthropic":
    try:
        from anthropic import Anthropic
        _anthropic = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
    except Exception as e:
        raise RuntimeError(f"Falha ao inicializar Anthropic client: {e}")
else:
    raise ValueError(f"LLM_PROVIDER inv√°lido: {LLM_PROVIDER}")

def _approx_tokens(txt: str) -> int:
    # heur√≠stica: ~4 chars por token (ajuste se quiser)
    return max(1, math.ceil(len(txt) / 4))

def _context_window_from_env(model: str) -> int:
    # permite override espec√≠fico por modelo, ex.: LLM_CONTEXT_WINDOW_GPT_5=128000
    model_key = model.upper().replace("-", "_").replace(".", "_")
    return int(os.getenv(f"LLM_CONTEXT_WINDOW_{model_key}", os.getenv("LLM_CONTEXT_WINDOW", "32000")))

def _length_param_name(model: str) -> str:
    # modelos de racioc√≠nio ‚Üí max_completion_tokens; demais ‚Üí max_tokens
    m = model.lower()
    return "max_completion_tokens" if m.startswith(("gpt-5", "o1", "o3", "o4-mini")) else "max_tokens"

def _cap_limit_tokens(model: str, messages, desired: int) -> int:
    ctx_window = _context_window_from_env(model)
    in_tokens = sum(_approx_tokens(m.get("content", "")) for m in messages)
    safety = int(os.getenv("LLM_SAFETY_TOKENS", "512"))
    available = ctx_window - in_tokens - safety
    # evita negativo e limita ao desejado
    return max(1, min(desired, max(1, available)))


# ===================== Grounding / Prompt =====================
SYSTEM_PROMPT_SENTENCA = """
Voc√™ √© um juiz que redige senten√ßas **apenas** com base no CONTEXTO fornecido.
Regras (obrigat√≥rias):
0) Inicie a senten√ßa com o texto "√â o que havia a relatar. Relatado o feito, DECIDO."
1) Use exclusivamente informa√ß√µes do bloco CONTEXTO.
2) N√£o cite lei/jurisprud√™ncia/precedente que n√£o esteja no CONTEXTO.
3) Linguagem t√©cnica jur√≠dica brasileira; nada de analogias criativas ou suposi√ß√µes.
4) **Siga rigorosamente a ESTRUTURA DA SENTEN√áA abaixo, mas sem citar os t√≠tulos.**
5) ** N√£o refira aos documentos de refer√™ncia, como em "conforme ilustra a jurisprud√™ncia colacionada nos **documentos de refer√™ncia**". Atue como se estivesse lido os documentos de refer√™ncia e incorporado seu conhecimento. Cite diretamente apenas lei e jurisprud√™ncia encontradas nos documentos de refer√™ncia, e n√£o os textos pr√≥prios do documento.
6) **Exce√ß√£o √†s regras 1‚Äì2:** o BLOCO DE CONCLUS√ÉO OBRIGAT√ìRIA deve ser reproduzido **exatamente** como fornecido ao final, **mesmo que n√£o esteja no CONTEXTO**.
7) Antes de finalizar, verifique que cada asser√ß√£o feita est√° explicitamente suportada pelo CONTEXTO.
""" 

def _safe_pick(d: Dict[str, Any], keys: List[str], default: str = "") -> str:
    for k in keys:
        v = d.get(k)
        if isinstance(v, str) and v.strip():
            return v
    return default

def _trim_text(s: str, max_chars: int) -> str:
    if len(s) <= max_chars:
        return s
    return s[: max_chars - 3] + "..."

def build_context(exemplos: List[Dict[str, Any]], *, max_docs: int = 5, max_chars_per_doc: int = 10000) -> str:
    if not exemplos:
        return "(nenhum documento fornecido)"

    blocos = []
    for i, doc in enumerate(exemplos[:max_docs]):
        titulo = _safe_pick(doc, ["titulo", "title", "nome"], default=f"Documento {i+1}")
        # üëá juntar relatorio, fundamentacao, dispositivo
        conteudo = ""
        for k in ["conteudo", "content", "texto", "trecho", "body", "relatorio", "fundamentacao", "dispositivo"]:
            v = doc.get(k)
            if isinstance(v, str) and v.strip():
                conteudo += v.strip() + "\n\n"
        conteudo = _trim_text(conteudo.strip(), max_chars_per_doc) if conteudo else "[sem conte√∫do]"
        blocos.append(f"Documento {i+1}: {titulo}\n---\n{conteudo}\n")

    return "\n\n".join(blocos)

def _montar_mensagens_sentenca(relatorio: str, contexto: str, instrucoes_usuario: Optional[str]) -> List[Dict[str, str]]:
    relatorio = (relatorio or "").strip()
    contexto = (contexto or "").strip()
    instr = (instrucoes_usuario or "").strip()
    instr_block = f"INSTRU√á√ïES ADICIONAIS DO USU√ÅRIO:\n{instr}\n\n" if instr else ""

    user_msg = f"""
TAREFA: Gerar senten√ßa (fundamenta√ß√£o + dispositivo) **estritamente** baseada no CONTEXTO.

NOVO RELAT√ìRIO:
{relatorio}

{instr_block}
=== CONTEXTO (√∫nica fonte de verdade) ===

{contexto}
=== FIM DO CONTEXTO ===

## ESTRUTURA DA SENTEN√áA

### 0. JULGAMENTO ANTECIPADO
- Verifique no RELAT√ìRIO se houve produ√ß√£o de provas, como audi√™ncia de instru√ß√£o e julgamento, per√≠cia t√©cnica, etc. Caso as partes n√£o tenham produzido provas, anuncie o julgamento antecipado previsto no art. 355, conforme o CONTEXTO.

### 1. QUEST√ïES PRELIMINARES
- Analise o processo e identifique se h√°, na CONTESTA√á√ÉO quest√µes PRELIMINARES suscitadas (exemplo: in√©pcia da inicial, impugna√ß√£o ao valor da causa, falta de interesse de agir, prescri√ß√£o, etc.).
- Se houver preliminares, desenvolva a fundamenta√ß√£o para cada uma delas separadamente.
- Se n√£o houver preliminares, escreva a frase "Ausentes quest√µes preliminares, passo ao m√©rito." e siga para o m√©rito.

### 2. M√âRITO
- Inicie afirmando claramente o(s) fato(s) que constitui(em) a causa de pedir do autor.
- Em seguida, apresente o principal argumento do r√©u em sua defesa.
- Desenvolva a fundamenta√ß√£o com base nos documentos de refer√™ncia, analisando:
  - Os fatos comprovados nos autos
  - As provas produzidas
  - A legisla√ß√£o aplic√°vel
  - A jurisprud√™ncia pertinente
  - A doutrina relevante

#### REGRAS IMPORTANTES PARA A FUNDAMENTA√á√ÉO:
- As cita√ß√µes de lei, doutrina ou jurisprud√™ncia devem ser reproduzidas **EXATAMENTE** como constam nos documentos de refer√™ncia, sem altera√ß√µes.
- A argumenta√ß√£o deve ser coerente, l√≥gica e completa.
- Utilize linguagem t√©cnica-jur√≠dica apropriada.
- Analise todos os pedidos formulados na inicial.

### 3. DISPOSITIVO
- Elabore o dispositivo da senten√ßa, decidindo sobre todos os pedidos.
- Fixe os honor√°rios advocat√≠cios conforme crit√©rios do art. 85 do CPC.

### 4. CONCLUS√ÉO OBRIGAT√ìRIA
Ap√≥s o dispositivo e a condena√ß√£o em honor√°rios, encerre a senten√ßa com **EXATAMENTE** o seguinte texto, **sem nenhuma altera√ß√£o**:

"Opostos embargos de declara√ß√£o com efeito modificativo, intime-se a parte embargada para, querendo, manifestar-se no prazo de 05 (cinco) dias. (art. 1.023, ¬ß 2¬∫, do CPC/2015), e decorrido o prazo, com ou sem manifesta√ß√£o, voltem conclusos.

Na hip√≥tese de interposi√ß√£o de recurso de apela√ß√£o, intime-se a parte apelada para apresentar contrarraz√µes (art. 1010, ¬ß1¬∫, do CPC/2015). Havendo alega√ß√£o ‚Äì em sede de contrarraz√µes - de quest√µes resolvidas na fase de conhecimento as quais n√£o comportaram agravo de instrumento, intime-se a parte adversa (recorrente) para, em 15 (quinze) dias, manifestar-se a respeito delas (art. 1.009, ¬ß¬ß 1¬∫ e 2¬∫, do CPC/2015). Havendo interposi√ß√£o de apela√ß√£o adesiva, intime-se a parte apelante para contrarraz√µes, no prazo de 15 (quinze) dias (art. 1010, ¬ß2¬∫, do CPC/2015). Em seguida, com ou sem resposta, sigam os autos ao e. Tribunal de Justi√ßa do Estado de Pernambuco, com os cumprimentos deste Ju√≠zo (art. 1010, ¬ß3¬∫, do CPC/2015).

Ap√≥s o tr√¢nsito em julgado, nada mais sendo requerido, arquivem-se os autos, com as cautelas de estilo, independentemente de nova determina√ß√£o.

Comunica√ß√µes processuais necess√°rias.

Cumpra-se.
Recife-PE, data da assinatura digital.

Maria Bet√¢nia Martins da Hora

Ju√≠za de Direito"

## INSTRU√á√ïES FINAIS
- Leia atentamente o relat√≥rio e todos os documentos de refer√™ncia antes de iniciar a reda√ß√£o.
- **Siga rigorosamente a estrutura indicada acima.**
- Certifique-se de que o texto final est√° coeso, coerente e tecnicamente preciso.
- **N√£o omita** nenhum dos elementos obrigat√≥rios da senten√ßa.
- As cita√ß√µes de leis, doutrina e jurisprud√™ncia devem ser exatamente iguais √†s dos documentos de refer√™ncia.
"""
    return [
        {"role": "system", "content": SYSTEM_PROMPT_SENTENCA},
        {"role": "user", "content": user_msg},
    ]


# ===================== Chamada √†s APIs =====================

def _extract_text_from_response(content: Any) -> str:
    """Extrai texto de respostas do Anthropic (content blocks)."""
    try:
        parts = []
        for block in content or []:
            # Estrutura comum: {"type": "text", "text": "..."}
            t = block.get("text") if isinstance(block, dict) else None
            if isinstance(t, str) and t:
                parts.append(t)
        return "".join(parts)
    except Exception:
        return ""


def _call_llm(*, messages: List[Dict[str, str]], on_progress: Optional[Callable[[str], None]] = None) -> str:
    max_retries = 5
    base_delay = 1
    param_name = _length_param_name(LLM_MODEL)
    limit = _cap_limit_tokens(LLM_MODEL, messages, LLM_MAX_TOKENS)
    
    for attempt in range(max_retries):
        try:
            if on_progress:
                on_progress(f"ü§ñ Consultando {LLM_PROVIDER.capitalize()} ({LLM_MODEL})... (Tentativa {attempt+1})")

            if LLM_PROVIDER == "openai":
           
                kwargs = {
                    "model": LLM_MODEL,
                    "messages": messages,
                    param_name: limit,           
                }

                # gpt-5 n√£o aceita temperature ‚â† 1
                if not LLM_MODEL.startswith("gpt-5"):
                    kwargs["temperature"] = LLM_TEMPERATURE

                seed_env = os.getenv("LLM_SEED")
                if seed_env and seed_env.isdigit():
                    kwargs["seed"] = int(seed_env)

                resp = _openai.chat.completions.create(**kwargs)
                return (resp.choices[0].message.content or "").strip()

            else:  # anthropic
                resp = _anthropic.messages.create(
                    model=LLM_MODEL,
                    max_tokens=LLM_MAX_TOKENS,
                    temperature=LLM_TEMPERATURE,
                    messages=messages,
                )
                # extrai texto dos blocks:
                text = "".join([b.get("text","") for b in getattr(resp, "content", []) if isinstance(b, dict)])
                return (text or "").strip()

        except Exception as e:
            # backoff simples para erros transit√≥rios
            transient = ["529", "overloaded", "500", "503", "rate_limit", "timeout"]
            if any(t in str(e).lower() for t in transient) and attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                if on_progress: on_progress(f"‚è≥ API indispon√≠vel. Tentando de novo em {delay:.2f}s...")
                time.sleep(delay)
            else:
                if on_progress: on_progress(f"‚ùå Erro na chamada da API {LLM_PROVIDER}: {e}")
                return f"Erro na chamada da API {LLM_PROVIDER}: {e}"
    return "Erro: A chamada da API falhou ap√≥s m√∫ltiplas tentativas."

# ===================== Fun√ß√£o principal =====================

async def gerar_sentenca_llm(
    *,
    relatorio: str,
    exemplos: Optional[List[Dict[str, Any]]] = None,
    docs: Optional[List[Dict[str, Any]]] = None,   # <- retrocompat√≠vel com main.py
    instrucoes_usuario: Optional[str] = None,
    on_progress: Optional[Callable[[str], None]] = None,
) -> str:
    if exemplos is None and docs is not None:
        exemplos = docs

    if on_progress: on_progress("üìö Preparando CONTEXTO...")
    contexto = build_context(exemplos or [])

    if on_progress: on_progress("‚úçÔ∏è Montando mensagens...")
    messages = _montar_mensagens_sentenca(relatorio, contexto, instrucoes_usuario)

    if on_progress: on_progress("üéØ Gerando senten√ßa...")

    # roda a chamada bloqueante em thread, j√° que o endpoint √© async
    loop = asyncio.get_running_loop()
    resultado = await loop.run_in_executor(None, lambda: _call_llm(messages=messages, on_progress=on_progress))

    if on_progress: on_progress("‚úÖ Senten√ßa gerada com sucesso!")
    return resultado


__all__ = [
    "gerar_sentenca_llm",
    "build_context",
]
